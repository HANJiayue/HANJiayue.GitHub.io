---
title: "TDCC: top‐down semantic aggregation for color constancy"
collection: publications
permalink: /publication/2019tdcc
date: 2019
venue: 'IET Image Processing'
paperurl: ''
citation: ' Li X*, Zhu Y, Han J, et al. TDCC: top‐down semantic aggregation for color constancy[J]. IET Image Processing, 2019, 13(11): 1944-1950.'
---
Color constancy considers the problem of restoring the original color of an illuminated scene. Benefiting from the development of Convolutional Neural Network (CNN), substantial progress on color constancy has been made. High-level features of CNN structure contain semantic information while low-level features show local details. If both are taken into account, they would help achieve a more accurate illuminant estimation. However, previous works paid little attention to the latter for there lacks frameworks which can combine those two kinds of features together. Inspired by the pyramid model, a top-down network that successively propagates high-level information to low-level layers is proposed. This network, named Top-down Semantic Aggregation for Color Constancy (TDCC), takes full advantage of the multi-scale representations with strong semantics. As a result, objects with intrinsic colors are captured and a better estimation is obtained. Experiments on three benchmark datasets demonstrate that TDCC significantly outperforms state-of-the-art color constancy methods.


[Download paper here](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-ipr.2019.0480)

Recommended citation:  Li X*, Zhu Y, Han J, et al. TDCC: top‐down semantic aggregation for color constancy[J]. IET Image Processing, 2019, 13(11): 1944-1950.
